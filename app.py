import streamlit as st
import requests
from PIL import Image
import io
import re
from streamlit_drawable_canvas import st_canvas

# ğŸ§­ Configuration gÃ©nÃ©rale
st.set_page_config(page_title="OCR Intelligent", page_icon="ğŸ”", layout="centered")
st.title("ğŸ§  OCR IndexÃ© avec Zone DessinÃ©e")

# ğŸ¯ Champs Ã  extraire
target_fields = ["Voc", "Isc", "Pmax", "Vpm", "Ipm"]
field_aliases = {
    "voc": "Voc", "isc": "Isc", "pmax": "Pmax",
    "vpm": "Vpm", "ipm": "Ipm", "lpm": "Ipm"
}

# ğŸ“‰ PrÃ©traitement image (rotation + redimensionnement)
def preprocess_image(img, rotation):
    if rotation:
        img = img.rotate(-rotation, expand=True)
    max_width = 1024
    if img.width > max_width:
        ratio = max_width / float(img.width)
        img = img.resize((max_width, int(img.height * ratio)), Image.Resampling.LANCZOS)
    return img

# ğŸ” OCR via API OCR.Space
def ocr_space_api(img_bytes, api_key="helloworld"):  # âš ï¸ Remplace par ta vraie clÃ© API
    try:
        response = requests.post(
            "https://api.ocr.space/parse/image",
            files={"filename": ("image.jpg", img_bytes, "image/jpeg")},
            data={"apikey": api_key, "language": "eng", "isOverlayRequired": False}
        )
        result = response.json()
        return result.get("ParsedResults", [{}])[0].get("ParsedText", "")
    except Exception as e:
        return f"[Erreur OCR] {e}"

# ğŸ§  Indexation des champs reconnus + alias OCR
def index_and_match_fields_with_alias(text, field_keys, aliases):
    lines = [line.strip() for line in text.splitlines() if line.strip()]
    raw_fields, raw_values = [], []
    for line in lines:
        if line.endswith(":"):
            key = line.rstrip(":").lower().strip()
            if key in aliases:
                raw_fields.append(aliases[key])
    for line in lines:
        match = re.match(r"^\d+[.,]?\d*\s*[A-Za-z%Î©VWAm]*$", line)
        if match:
            raw_values.append(match.group(0).strip())
    result = {raw_fields[i]: raw_values[i] for i in range(min(len(raw_fields), len(raw_values)))}
    return {key: result.get(key, "Non dÃ©tectÃ©") for key in field_keys}

# ğŸ“¥ Import dâ€™image
uploaded_file = st.file_uploader("ğŸ“¤ Importer une image technique", type=["jpg", "jpeg", "png"])
if uploaded_file:
    img = Image.open(uploaded_file)
    rotation = st.selectbox("ğŸ” Rotation ?", [0, 90, 180, 270], index=0)
    img = preprocess_image(img, rotation)
    st.image(img, caption="ğŸ–¼ï¸ Image chargÃ©e", use_container_width=False)

    st.markdown("### âœï¸ Dessine une zone rectangulaire Ã  analyser")

    canvas_result = st_canvas(
        background_image=img,
        drawing_mode="rect",
        stroke_width=2,
        stroke_color="orange",
        fill_color="rgba(255,165,0,0.3)",
        update_streamlit=True,
        height=img.height,
        width=img.width,
        key="canvas"
    )

    # âœ‚ï¸ Si une zone est dessinÃ©e
    if canvas_result.json_data and canvas_result.json_data["objects"]:
        rect = canvas_result.json_data["objects"][0]
        x, y = rect["left"], rect["top"]
        w, h = rect["width"], rect["height"]
        cropped_img = img.crop((x, y, x + w, y + h))
        st.image(cropped_img, caption="ğŸ“Œ Zone sÃ©lectionnÃ©e", use_container_width=False)

        # ğŸ” OCR sur la zone rognÃ©e
        img_bytes = io.BytesIO()
        cropped_img.save(img_bytes, format="JPEG", quality=70)
        img_bytes.seek(0)
        raw_text = ocr_space_api(img_bytes)

        with st.expander("ğŸ“„ Texte OCR brut"):
            st.text(raw_text)

        results = index_and_match_fields_with_alias(raw_text, target_fields, field_aliases)
        st.subheader("ğŸ“Š Champs techniques extraits :")
        for key in target_fields:
            st.write(f"ğŸ”¹ **{key}** â†’ {results.get(key)}")
    else:
        st.info("ğŸ–±ï¸ Dessine un rectangle pour dÃ©clencher lâ€™analyse.")
